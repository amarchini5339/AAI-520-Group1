{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea68106",
   "metadata": {},
   "source": [
    "## https://github.com/amarchini5339/AAI-520-Group1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf232b",
   "metadata": {},
   "source": [
    "## /src/RouterMain.py\n",
    "This is the routing agent that will call all of the other agents.  It will first lookup the company name in an attempt to determine if it is an equity or not.  If it is an equity, it will bull SEC filings and financial data from Yahoo Finance.  I will then merge with the non-equity branch and pull economic data from FRED and news sites.  It will combine all of this data to create a final report and make a final reccomendation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd260313",
   "metadata": {},
   "source": [
    "## Main Orchestration Engine - RouterMain.py\n",
    "\n",
    "###  **Core System Controller**\n",
    "\n",
    "This cell implements the **central workflow coordinator** for our autonomous financial research system. It defines the main flow that:\n",
    "\n",
    "### **Key Responsibilities:**\n",
    "- **Orchestrates multiple specialized AI agents** in a coordinated sequence\n",
    "- **Implements intelligent routing logic** based on security type (Equity vs Non-Equity)\n",
    "- **Manages the complete research pipeline** from company identification to final recommendation\n",
    "- **Handles error recovery** and maintains state throughout the analysis process\n",
    "\n",
    "### **Workflow Pattern Implementation:**\n",
    "- **ROUTING PATTERN**: Directs analysis to appropriate specialists based on security classification\n",
    "- **SEQUENTIAL EXECUTION**: Coordinates agents in logical order (SEC ‚Üí Yahoo ‚Üí FRED ‚Üí News ‚Üí Synthesis)\n",
    "- **ERROR HANDLING**: Graceful degradation when individual agents encounter issues\n",
    "\n",
    "### **Agent Coordination:**\n",
    "The flow intelligently routes analysis through four specialized research agents, collects their findings, and uses advanced AI (GPT-5) to synthesize a comprehensive investment recommendation with clear bull/bear cases and macroeconomic impact analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/RouterMain.py\n",
    "# Main flow router for financial analysis using multiple agents\n",
    "from crewai.flow.flow import Flow, listen, start, router, or_\n",
    "from crewai import Agent, Crew, Task\n",
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "\n",
    "# Import yahoo finance ticker finder\n",
    "from researchers.tools import yahoo_find_ticker as yft\n",
    "\n",
    "# Import necessary functions and classes from other researchers\n",
    "from researchers.SECresearcher import run_sec_filing_agent, _safe_parse_json, _load_openai_client\n",
    "from researchers.News_Agent_Crew import news_agent_crew\n",
    "from researchers.FREDresearcher import create_crewai_fred_agent\n",
    "from researchers.YahooFinanceCrew import run_yahoo_finance_agent\n",
    "\n",
    "# Import logging for debugging\n",
    "import logging\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define the main financial analysis flow\n",
    "class FinancialAnalysisFlow(Flow):\n",
    "    # Use a lightweight model for intermediate steps\n",
    "    model = \"gpt-5-mini\"\n",
    "\n",
    "    # Initialize the flow with tracing enabled\n",
    "    def __init__(self):\n",
    "        # Initialize state and logging\n",
    "        super().__init__(tracing=True)\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.log = logging.getLogger(__name__)\n",
    "        self.state['debug'] = False  # default debug to False\n",
    "        self.client = _load_openai_client()  # Initialize OpenAI client\n",
    "\n",
    "    # Define the start of the flow\n",
    "    @start()\n",
    "    def get_ticker(self):\n",
    "        self.log.info(\"Starting flow\")\n",
    "        print(f\"Flow State ID: {self.state['id']}\")\n",
    "\n",
    "        if 'debug' in self.state:\n",
    "            # Get debug flag from state, default to False\n",
    "            self.state['debug'] = self.state.get('debug', False)\n",
    "\n",
    "        # Get user-provided prompt or fallback to Microsoft\n",
    "        prompt = self.state.get(\"prompt\", \"Microsoft\")\n",
    "        if self.state[\"debug\"]:\n",
    "            print(f\"Prompt: {prompt}\")\n",
    "\n",
    "        try:\n",
    "            best = yft.yahoo_find_ticker(prompt)\n",
    "            self.state[\"best\"] = best\n",
    "            print(best)\n",
    "            return best\n",
    "        except Exception as e:\n",
    "            best = {\"symbol\": \"ERROR\", \"name\": str(e), \"exch\": \"\", \"exchDisp\": \"\", \"type\": \"\", \"typeDisp\": \"\"}\n",
    "            self.state[\"best\"] = best\n",
    "            return best\n",
    "    # Define the router for equity check\n",
    "    @router(get_ticker)\n",
    "    def check_equity(self):\n",
    "        type = self.state[\"best\"][\"typeDisp\"]\n",
    "\n",
    "        if type == \"\":\n",
    "            return \"UNKNOWN_BRANCH\"\n",
    "        elif type == \"EQUITY\":\n",
    "            return \"EQUITY_BRANCH\"\n",
    "        else:\n",
    "            return \"NON_EQUITY_BRANCH\"\n",
    "    \n",
    "    # Define the handler for unknown security types\n",
    "    @listen('UNKNOWN_BRANCH')\n",
    "    def handle_unknown(self):\n",
    "        symbol = self.state[\"best\"][\"symbol\"]\n",
    "        print(f\"Unknown branch for {symbol} - cannot proceed with research.\")\n",
    "        self.state[\"error\"] = f\"Unknown security type for symbol: {symbol}\"\n",
    "        return 'ERROR_DONE'\n",
    "    \n",
    "    # Define the handler for equity securities\n",
    "    @listen('EQUITY_BRANCH')\n",
    "    def get_sec_agent(self):\n",
    "        symbol = self.state[\"best\"][\"symbol\"]\n",
    "        print(f\"Equity branch for {symbol} - running SEC research agent...\")\n",
    "\n",
    "        try:\n",
    "            # Run the SEC filing analysis agent\n",
    "            result = run_sec_filing_agent({\"ticker\": symbol})\n",
    "            self.state[\"sec_result\"] = result\n",
    "            if self.state[\"debug\"]:\n",
    "                print(self.state[\"sec_result\"])\n",
    "            print(f\"SEC Research completed for {symbol}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running SEC agent: {e}\")\n",
    "            self.state[\"sec_result\"] = {}\n",
    "        return \"SEC_DONE\"\n",
    " \n",
    "    @listen('get_sec_agent')\n",
    "    def get_yahoo_agent(self):\n",
    "        symbol = self.state[\"best\"][\"symbol\"]\n",
    "        # Run the Yahoo Finance research agent\n",
    "        yahoo_result = run_yahoo_finance_agent({\"ticker\": symbol})\n",
    "        self.state[\"yahoo_result\"] = yahoo_result\n",
    "        if self.state[\"debug\"]:\n",
    "            print(self.state[\"yahoo_result\"])\n",
    "        print(f\"Yahoo branch for {symbol} - proceeding to do yahoo research\")\n",
    "        return 'YAHOO_DONE'\n",
    "    \n",
    "    @listen(or_('NON_EQUITY_BRANCH', 'get_yahoo_agent'))\n",
    "    def get_fred_agent(self):\n",
    "        symbol = self.state[\"best\"][\"symbol\"]\n",
    "        try:\n",
    "            print(f\"FRED branch for {symbol} - running FRED research agent...\")\n",
    "            # Create FRED agent\n",
    "            fred_agent = create_crewai_fred_agent(Agent)\n",
    "            # Create a task for economic analysis\n",
    "            task = Task(\n",
    "                description=f\"Analyze economic indicators from FRED for their impact on {symbol}\",\n",
    "                agent=fred_agent,\n",
    "                input_payload={\"ticker\": symbol},\n",
    "                expected_output=\"JSON with 1-5 rating and economic analysis\")\n",
    "\n",
    "            # Create and run the crew\n",
    "            crew = Crew(agents=[fred_agent], tasks=[task])\n",
    "            self.log.info(\"Starting economic analysis...\")\n",
    "            result = crew.kickoff()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running FRED agent: {e}\")\n",
    "            self.state[\"fred_result\"] = {}\n",
    "            return 'ERROR_DONE'\n",
    "\n",
    "        self.state[\"fred_result\"] = result\n",
    "        if self.state[\"debug\"]:\n",
    "            print(self.state[\"fred_result\"])\n",
    "        print(f\"Yahoo done branch for {symbol} - proceeding to do fred research\")\n",
    "        return 'FRED_DONE'\n",
    "    \n",
    "    @listen('get_fred_agent')\n",
    "    def get_news_agent(self):\n",
    "        symbol = self.state[\"best\"][\"symbol\"]\n",
    "        print(f\"News branch for {symbol} - proceeding to do news research\")\n",
    "        try:\n",
    "            # Run the News agent crew\n",
    "            result = news_agent_crew.kickoff(inputs={\"company\": symbol})\n",
    "            self.state[\"news_result\"] = result\n",
    "            if self.state[\"debug\"]:\n",
    "                print(self.state[\"news_result\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error running News agent: {e}\")\n",
    "            self.state[\"news_result\"] = {}\n",
    "            return 'ERROR_DONE'\n",
    "        print(f\"NewsAgent Crew completed for {symbol}\")\n",
    "        return 'NEWS_DONE'\n",
    "    \n",
    "    @listen('get_news_agent')\n",
    "    def finalize(self):\n",
    "        symbol = self.state[\"best\"][\"symbol\"]\n",
    "        print(self.state)\n",
    "        print(f\"Complete analysis for {symbol} - finalizing flow\")\n",
    "        try:\n",
    "            # Final synthesis using advanced model\n",
    "            response = self.client.chat.completions.create(\n",
    "            model=\"gpt-5\", # use advanced model for final synthesis\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a financial analysis expert.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Provide a rating from 1 'sell', 2 'underperform', 3 'hold', \"\n",
    "                        \"4 'outperform', 5 'strong buy' based on the following context. \"\n",
    "                        f\"SEC Report JSON: {self.state['sec_result']}. \"\n",
    "                        f\"FRED JSON: {self.state['fred_result']}. \"\n",
    "                        f\"News JSON: {self.state['news_result']}. \"\n",
    "                        f\"Yahooo Finance JSON: {self.state['yahoo_result']}. \"\n",
    "                        \"Respond with easy to read report only like rating and rationale. \"\n",
    "                        \"Create a concise rationale for your rating.  List bull and bear cases for investment.\"\n",
    "                        \"Explain how macroeconomic factors from FRED influenced your rating and how changing interest rates might impact the company's performance.\"\n",
    "                    ),\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during final analysis: {e}\")\n",
    "            self.state[\"final_result\"] = {}\n",
    "            return 'ERROR_DONE'\n",
    "\n",
    "        final_result = _safe_parse_json(response.choices[0].message.content)\n",
    "        self.state[\"final_result\"] = final_result\n",
    "        print(self.state[\"final_result\"])\n",
    "        print(f\"Final analysis completed for {symbol}\")\n",
    "        return self.state\n",
    "\n",
    "# --- Run the flow ---\n",
    "flow = FinancialAnalysisFlow()\n",
    "\n",
    "flow.plot()  # visualize flow\n",
    "\n",
    "# Example run using Apple as prompt\n",
    "result = flow.kickoff(inputs={\"prompt\": \"Apple\", \"debug\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d78362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>&amp; C:/Users/mikes/.conda/envs/py312_pyt/python.exe \"y:/My Drive/A520/project/AAI-520-Group1/src/RouterMain.py\"\n",
       " Flow Execution </p>\n",
       "<p>‚îÇ  Starting Flow Execution                                                                                                                                    <br />\n",
       "‚îÇ  Name: FinancialAnalysisFlow                                                                                                                        <br />\n",
       "‚îÇ  ID: cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13                                                                                                         <br />\n",
       "‚îÇ  Tool Args:                                                                                                                                          </p>\n",
       "<p>Plot saved as crewai_flow.html\n",
       "Flow started with ID: cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13\n",
       "üåä Flow: FinancialAnalysisFlow\n",
       "üåä Flow: FinancialAnalysisFlow\n",
       "Flow State ID: cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13\n",
       "Prompt: Apple\n",
       "{'symbol': 'AAPL', 'name': 'Apple Inc.', 'exch': 'NMS', 'exchDisp': 'NASDAQ', 'type': 'EQUITY', 'typeDisp': 'EQUITY'}\n",
       "Equity branch for AAPL - running SEC research agent...\n",
       "Ticker AAPL CIK=0000320193\n",
       "Most recent filing for CIK 0000320193: Form 10-Q, Accession 0000320193-25-000073, Filed on 2025-08-01\n",
       "üåä Flow: FinancialAnalysisFlow\n",
       "üåä Flow: FinancialAnalysisFlow\n",
       "{'final_result': {'rating': 3, 'rationale': 'Weighted score = 0.20<em>1.3538 (YoY) + 0.20</em>5 (profit) + 0.15<em>1 (debt) + 0.15</em>5 (income) + 0.30<em>4 (risk) = 3.37, which rounds to 3 (hold). Rationale:\n",
       "very strong profitability and positive net income lift the profile, but weak YoY growth and a high debt-to-equity ratio materially drag the score. The moderate risk/M&amp;A profile (regulatory and\n",
       "geopolitical headwinds vs. strong cash/liquidity) supports an outperform bias but not enough to overcome the other negatives, so a hold rating is appropriate.'}, 'financial_ratings': {'yoy':<br />\n",
       "{'yoy_growth': 6.768844826412347, 'ratintg': 1.3537689652824694, 'description': 'Year over year revenue growth as a percentage'}, 'profit': {'net_profit_margin': 26.482656457321124, 'rating': \n",
       "5, 'description': 'Net profit margin as a percentage'}, 'debt': {'debt_to_equity': 1.3941212213276621, 'rating': 1, 'description': 'Debt to equity ratio'}, 'income': {'net_income':\n",
       "107978000000, 'rating': 5, 'description': 'Positive net income'}}, 'risk_mna_rating': {'rating': 4, 'rationale': 'Apple‚Äôs risk profile is moderate: it faces material regulatory overhang (DMA<br />\n",
       "investigations with potential significant fines and App Store rule changes, DOJ antitrust case, Epic compliance scrutiny) that could pressure high-margin Services economics, plus\n",
       "supply-chain/geopolitical concentration in Asia, FX headwinds, and iPhone reliance. Offsetting these are very strong fundamentals‚Äî$140.8B in cash and securities, robust and rising gross     <br />\n",
       "margins (total 46.2%; Services 73.9%), resilient Services growth (+13%), and substantial capital return capacity ($110B buyback authorization, ongoing dividend). Liquidity, hedging programs,<br />\n",
       "and diversified global demand provide buffers against macro and component supply risks. Legal/tax contingencies appear manageable relative to cash flow and balance sheet strength. Netting   <br />\n",
       "these factors, the risk-adjusted outlook supports an outperform rather than a strong buy due to the elevated regulatory and geopolitical uncertainties.'}}\n",
       "SEC Research completed for AAPL                                                                                                                                                               <br />\n",
       "{'symbol': 'AAPL', 'rating': 4, 'confidence': 0.6800000000000002, 'timestamp': '2025-10-18T23:09:50.752179Z', 'source': 'YahooFinanceAgent', 'context': {'key_indicators': {'latest_close':   <br />\n",
       "252.2899932861328, 'first_date': '2024-10-11T00:00:00', 'last_date': '2025-10-17T00:00:00', '7d_return': -0.02235915805257971, '30d_return': 0.052567861472681665, '90d_return':\n",
       "0.24624425007258544, '1y_return': 0.11388336575800784, 'sma_20': 253.49299850463868, 'sma_50': 241.06519927978516, 'sma_200': 221.7284740447998, 'price_vs_sma20': -1, 'volatility_30d':      <br />\n",
       "0.016321981356258078, 'max_drawdown': -0.33360516168821136, 'rsi_14': 56.517437136137744}, 'fundamentals': {'market_cap': 3744081903616, 'trailing_pe': 38.341946, 'forward_pe': 30.359806,   <br />\n",
       "'peg_ratio': None, 'beta': 1.094}, 'earnings_event': {'last_earnings_date': None, 'pre7_return': None, 'post7_return': None}, 'rationale': 'mild_30d_momentum ; 90d_strong_up ; below_sma20 ; <br />\n",
       "low_volatility | pe=38.341946', 'fetch_seconds': 1.73, 'data_source': 'yfinance'}}\n",
       "Yahoo branch for AAPL - proceeding to do yahoo research\n",
       "FRED branch for AAPL - running FRED research agent...                                                                                                                                         <br />\n",
       "üåä Flow: FinancialAnalysisFlow                                                                                                                                                                <br />\n",
       "ID: cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13                                                                                                                                                      <br />\n",
       "‚îú‚îÄ‚îÄ Flow Method Step                                                                                                                                                                          <br />\n",
       "‚îú‚îÄ‚îÄ ‚úÖ Completed: get_ticker                                                                                                                                                                  <br />\n",
       "‚îú‚îÄ‚îÄ ‚úÖ Completed: check_equity                                                                                                                                                                <br />\n",
       "üåä Flow: FinancialAnalysisFlow\n",
       "ID: cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13\n",
       "‚îú‚îÄ‚îÄ Flow Method Step\n",
       "üåä Flow: FinancialAnalysisFlow\n",
       "ID: cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13\n",
       "‚îú‚îÄ‚îÄ Flow Method Step\n",
       "‚îú‚îÄ‚îÄ ‚úÖ Completed: get_ticker\n",
       "‚îú‚îÄ‚îÄ ‚úÖ Completed: check_equity\n",
       "üåä Flow: FinancialAnalysisFlow\n",
       "ID: cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13\n",
       "‚îú‚îÄ‚îÄ Flow Method Step\n",
       "{\n",
       "  \"rating\": 4,\n",
       "  \"analysis\": \"The current economic environment seems to be relatively favorable for AAPL stock performance. The Consumer Price Index (CPI) is showing a modest increase, which indicates stable\n",
       "inflation levels. The decrease in the Unemployment Rate suggests a stronger labor market, potentially leading to higher consumer spending on Apple products. The decline in the Federal Funds <br />\n",
       "Rate could make borrowing cheaper for businesses, including Apple, stimulating investment and growth. The positive change in Gross Domestic Product (GDP) and Industrial Production Index also<br />\n",
       "point towards a growing economy, which is usually beneficial for tech companies like Apple. Overall, these indicators collectively support a positive outlook for AAPL stock in this economic <br />\n",
       "environment.\",\n",
       "  \"details\": {\n",
       "    \"indicators\": {\n",
       "      \"CPIAUCSL\": {\n",
       "        \"description\": \"Consumer Price Index\",\n",
       "        \"latest_value\": 323.364,\n",
       "        \"previous_value\": 322.132,\n",
       "        \"pct_change\": 0.38245191412215207,\n",
       "        \"last_updated\": \"2025-08-01\"\n",
       "      },\n",
       "      \"UNRATE\": {\n",
       "        \"description\": \"Unemployment Rate\",\n",
       "        \"latest_value\": 4.3,\n",
       "        \"previous_value\": 4.2,\n",
       "        \"pct_change\": 2.3809523809523725,\n",
       "        \"last_updated\": \"2025-08-01\"\n",
       "      },\n",
       "      \"FEDFUNDS\": {\n",
       "        \"description\": \"Federal Funds Rate\",\n",
       "        \"latest_value\": 4.22,\n",
       "        \"previous_value\": 4.33,\n",
       "        \"pct_change\": -2.540415704387998,\n",
       "        \"last_updated\": \"2025-09-01\"\n",
       "      },\n",
       "      \"GDP\": {\n",
       "        \"description\": \"Gross Domestic Product\",\n",
       "        \"latest_value\": 30485.729,\n",
       "        \"previous_value\": 30042.113,\n",
       "        \"pct_change\": 1.4766471319776946,\n",
       "        \"last_updated\": \"2025-04-01\"\n",
       "      },\n",
       "      \"INDPRO\": {\n",
       "        \"description\": \"Industrial Production Index\",\n",
       "        \"latest_value\": 103.9203,\n",
       "        \"previous_value\": 103.8194,\n",
       "        \"pct_change\": 0.09718800147178251,\n",
       "        \"last_updated\": \"2025-08-01\"\n",
       "      }\n",
       "    },\n",
       "    \"timestamp\": \"2025-10-18T23:09:56.439123\"\n",
       "  }\n",
       "}                                                                                                                                                                                             <br />\n",
       "Yahoo done branch for AAPL - proceeding to do fred research                                                                                                                                   <br />\n",
       "News branch for AAPL - proceeding to do news research                                                                                                                                         <br />\n",
       "üåä Flow: FinancialAnalysisFlow                                                                                                                                                                <br />\n",
       "ID: cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13                                                                                                                                                      <br />\n",
       "‚îú‚îÄ‚îÄ Flow Method Step                                                                                                                                                                          <br />\n",
       "‚îú‚îÄ‚îÄ ‚úÖ Completed: get_ticker                                                                                                                                                                  <br />\n",
       "üåä Flow: FinancialAnalysisFlow\n",
       "ID: cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13\n",
       "‚îú‚îÄ‚îÄ Flow Method Step\n",
       "‚îú‚îÄ‚îÄ ‚úÖ Completed: get_ticker\n",
       "<code>json\n",
       "{\n",
       "  \"company\": \"AAPL\",\n",
       "  \"date\": \"2024-07-28T12:00:00\",\n",
       "  \"sentiment_summary\": {\n",
       "    \"overall_sentiment\": \"Positive\",\n",
       "    \"positive_articles\": 6,\n",
       "    \"neutral_articles\": 3,\n",
       "    \"negative_articles\": 1,\n",
       "    \"main_topic\": [\n",
       "      \"AI and GenAI strategy\",\n",
       "      \"Apple Intelligence features\",\n",
       "      \"WWDC announcements\",\n",
       "      \"iPhone sales and market performance\",\n",
       "      \"Regulatory scrutiny and antitrust concerns\"\n",
       "    ],\n",
       "    \"good_news\": [\n",
       "      \"Positive reception to Apple Intelligence, integrating AI across devices.\",\n",
       "      \"Strong demand for iPhone 15 Pro Max and upcoming iPhone 16.\",\n",
       "      \"Optimism around AI features driving a new upgrade cycle.\",\n",
       "      \"Analysts predict significant revenue growth from AI integration.\",\n",
       "      \"Apple's focus on on-device processing for AI enhances privacy.\"\n",
       "    ],\n",
       "    \"bad_news\": [\n",
       "      \"Ongoing antitrust concerns and regulatory scrutiny, particularly in the EU.\",\n",
       "      \"Challenges in the Chinese market affecting sales in Q1.\"\n",
       "    ],\n",
       "    \"neutral_news\": [\n",
       "      \"Discussions around the timing and full rollout of Apple Intelligence.\",\n",
       "      \"Comparisons with competitors' AI strategies.\",\n",
       "      \"General market analysis of Apple's position.\"\n",
       "    ]\n",
       "  },\n",
       "  \"feedback\": \"Analysis successfully fetched and summarized recent news for AAPL. Sentiment is predominantly positive due to AI strategy, with some neutral and negative points regarding       \n",
       "regulatory issues and specific market challenges. The analysis is comprehensive and follows the required format.\"\n",
       "}</code>                                                                                                                                                                                           <br />\n",
       "NewsAgent Crew completed for AAPL                                                                                                                                                             <br />\n",
       "{'id': 'cb7d2d5c-a1f0-4e4f-a461-ff16549c3c13', 'debug': True, 'prompt': 'Apple', 'best': {'symbol': 'AAPL', 'name': 'Apple Inc.', 'exch': 'NMS', 'exchDisp': 'NASDAQ', 'type': 'EQUITY',      <br />\n",
       "'typeDisp': 'EQUITY'}, 'sec_result': {'final_result': {'rating': 3, 'rationale': 'Weighted score = 0.20</em>1.3538 (YoY) + 0.20<em>5 (profit) + 0.15</em>1 (debt) + 0.15<em>5 (income) + 0.30</em>4 (risk) = 3.37,\n",
       "which rounds to 3 (hold). Rationale: very strong profitability and positive net income lift the profile, but weak YoY growth and a high \n",
       "(truncated for brevity) debt-to-\n",
       "Complete analysis for AAPL - finalizing flow                                                                                                                                                    </p>\n",
       "<p>**üåä Flow: FinancialAnalysisFlow\n",
       "Rating: 4 ‚Äì Outperform</p>\n",
       "<p>Rationale:\n",
       "- Strong profitability and cash generation (net profit margin ~26%, large net income) and a moderate risk profile support upside.\n",
       "- Macro tailwinds (FRED rating 4) and broadly positive AI/news sentiment point to a favorable near- to medium-term setup, while price action shows strong 90-day momentum despite a minor     <br />\n",
       "pullback below the 20-day SMA.\n",
       "- Offsets: elevated valuation (P/E ~38x trailing, ~30x forward), modest YoY growth, regulatory overhang, and a higher debt-to-equity reading in the provided data. Netting these, risk/reward <br />\n",
       "skews positive, but not to ‚Äústrong buy.‚Äù</p>\n",
       "<p>Bull case:\n",
       "- AI-driven upgrade cycle (Apple Intelligence) boosts iPhone and Services; privacy-focused on‚Äëdevice AI differentiates the ecosystem.\n",
       "- Services growth with high margins supports earnings durability and multiple.\n",
       "- Robust balance sheet and capital returns ($110B buyback authorization, ongoing dividend) enhance per‚Äëshare EPS growth.\n",
       "- Positive macro backdrop (GDP growth, easing Fed funds, stable inflation) supports consumer demand and equity multiples.\n",
       "- Strong 90-day momentum and improving operating leverage.</p>\n",
       "<ul>\n",
       "<li>Valuation leaves little room for execution slips if growth remains single-digit.</li>\n",
       "<li>Debt-to-equity in the provided data is elevated; higher rates or tighter credit could reduce buyback efficiency and flexibility.</li>\n",
       "<li>Near-term technicals: price just below 20-day SMA; potential consolidation after a strong run.</li>\n",
       "</ul>\n",
       "<p>Macro and interest rates:\n",
       "- FRED indicators (rising GDP and industrial production, modest CPI, slightly lower Fed funds) supported moving to Outperform by signaling a resilient consumer and benign inflation backdrop,\n",
       "which helps premium devices and services.\n",
       "- Falling or stable rates tend to: support equity multiples, lower discount rates on future cash flows, ease financing, and make large buybacks more accretive‚Äîtailwinds for Apple.\n",
       "- Rising rates would likely: compress valuation multiples (especially for mega-cap growth), increase financing costs for capital returns, strengthen the USD (pressuring international revenue),\n",
       "and potentially soften consumer demand.**</p>\n",
       "<p>Final analysis completed for AAPL</p>\n",
       "<p>‚úÖ Flow Finished: FinancialAnalysisFlow</p>\n",
       "<p>‚îú‚îÄ‚îÄ Flow Method Step</p>\n",
       "<p>‚îú‚îÄ‚îÄ ‚úÖ Completed: get_ticker</p>\n",
       "<p>‚îú‚îÄ‚îÄ ‚úÖ Completed: check_equity</p>\n",
       "<p>‚îú‚îÄ‚îÄ ‚úÖ Completed: get_sec_agent</p>\n",
       "<p>‚îú‚îÄ‚îÄ ‚úÖ Completed: get_yahoo_agent</p>\n",
       "<p>‚îú‚îÄ‚îÄ ‚úÖ Completed: get_fred_agent</p>\n",
       "<p>‚îú‚îÄ‚îÄ ‚úÖ Completed: get_news_agent</p>\n",
       "<p>‚îî‚îÄ‚îÄ ‚úÖ Completed: finalize</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import markdown\n",
    "\n",
    "with open(\"TerminalOutput.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    md_content = f.read()\n",
    "\n",
    "html = markdown.markdown(md_content)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ddb99",
   "metadata": {},
   "source": [
    "![Alt text](crewflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5629a",
   "metadata": {},
   "source": [
    "## /src/researchers/tools/yahoo_find_ticker.py\n",
    "File to lookup company name on Yahoo Finance and attempt to find stock ticker\n",
    "\n",
    "Function created completely with ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81389f58",
   "metadata": {},
   "source": [
    "## Company Ticker Lookup Service - yahoo_find_ticker.py\n",
    "\n",
    "### üîç **Intelligent Company Identification**\n",
    "\n",
    "This cell implements a **robust ticker symbol resolution service** that converts company names into official stock symbols and security information.\n",
    "\n",
    "### **Key Features:**\n",
    "\n",
    "**Dual-API Architecture:**\n",
    "- **Primary Endpoint**: Uses Yahoo Finance's modern search API for accurate symbol resolution\n",
    "- **Fallback Endpoint**: Automatically switches to legacy autocomplete API if primary fails\n",
    "- **Retry Logic**: Implements intelligent retry mechanism with exponential backoff for network resilience\n",
    "\n",
    "**Advanced Filtering & Normalization:**\n",
    "- **Security Type Filtering**: Can filter by EQUITY, ETF, or other security types\n",
    "- **Exchange Filtering**: Supports filtering by specific exchanges (NYSE, NASDAQ, etc.)\n",
    "- **Data Normalization**: Standardizes output format across different API responses\n",
    "- **Error Handling**: Comprehensive exception handling with meaningful error messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "SEARCH_URL = \"https://query2.finance.yahoo.com/v1/finance/search\"   # preferred\n",
    "AUTOC_URL  = \"https://autoc.finance.yahoo.com/autoc\"                # fallback\n",
    "\n",
    "def _session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\n",
    "        # Some Yahoo endpoints 404/403 without a UA\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; ticker-lookup/1.0)\",\n",
    "        \"Accept\": \"application/json,text/javascript,*/*;q=0.1\",\n",
    "    })\n",
    "    retry = Retry(\n",
    "        total=3, backoff_factor=0.3,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\"]\n",
    "    )\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=retry))\n",
    "    return s\n",
    "\n",
    "def yahoo_find_ticker(\n",
    "    company_name: str,\n",
    "    exchanges: Optional[List[str]] = None,   # e.g. [\"NYSE\", \"NasdaqGS\"]\n",
    "    types: Optional[List[str]] = None,       # e.g. [\"EQUITY\", \"ETF\"]\n",
    "    return_all: bool = False\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Find a ticker by company name using Yahoo Finance.\n",
    "    Returns best dict match (default) or a list of matches if return_all=True.\n",
    "    \"\"\"\n",
    "    s = _session()\n",
    "\n",
    "    # --- Preferred endpoint ---\n",
    "    try:\n",
    "        r = s.get(SEARCH_URL, params={\"q\": company_name, \"lang\": \"en-US\", \"region\": \"US\"}, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        quotes = data.get(\"quotes\", []) or []\n",
    "\n",
    "        # Normalize + filter\n",
    "        def norm(q):\n",
    "            return {\n",
    "                \"symbol\": q.get(\"symbol\"),\n",
    "                \"name\": q.get(\"shortname\") or q.get(\"longname\") or q.get(\"quoteType\"),\n",
    "                \"exch\": q.get(\"exchange\"),\n",
    "                \"exchDisp\": q.get(\"exchDisp\") or q.get(\"fullExchangeName\"),\n",
    "                \"type\": q.get(\"quoteType\"),\n",
    "                \"typeDisp\": q.get(\"quoteType\"),\n",
    "            }\n",
    "\n",
    "        candidates = [norm(q) for q in quotes if q.get(\"symbol\")]\n",
    "        if types:\n",
    "            tset = {t.upper() for t in types}\n",
    "            candidates = [c for c in candidates if (c[\"type\"] or \"\").upper() in tset]\n",
    "        if exchanges:\n",
    "            eset = set(exchanges)\n",
    "            candidates = [c for c in candidates if c[\"exchDisp\"] in eset or c[\"exch\"] in eset]\n",
    "\n",
    "        if candidates:\n",
    "            return candidates if return_all else candidates[0]\n",
    "    except requests.HTTPError:\n",
    "        pass  # fall through to fallback\n",
    "\n",
    "    # --- Fallback endpoint (older autocomplete) ---\n",
    "    try:\n",
    "        r = s.get(AUTOC_URL, params={\"query\": company_name, \"region\": 1, \"lang\": \"en\"}, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        rs = (r.json() or {}).get(\"ResultSet\", {}).get(\"Result\", []) or []\n",
    "        candidates = [{\n",
    "            \"symbol\": x.get(\"symbol\"),\n",
    "            \"name\": x.get(\"name\"),\n",
    "            \"exch\": x.get(\"exch\"),\n",
    "            \"exchDisp\": x.get(\"exchDisp\"),\n",
    "            \"type\": x.get(\"type\"),\n",
    "            \"typeDisp\": x.get(\"typeDisp\"),\n",
    "        } for x in rs if x.get(\"symbol\")]\n",
    "\n",
    "        if types:\n",
    "            tset = {t.upper() for t in types}\n",
    "            candidates = [c for c in candidates if (c[\"typeDisp\"] or \"\").upper() in tset or (c[\"type\"] or \"\").upper() in tset]\n",
    "        if exchanges:\n",
    "            eset = set(exchanges)\n",
    "            candidates = [c for c in candidates if c[\"exchDisp\"] in eset or c[\"exch\"] in eset]\n",
    "\n",
    "        if not candidates:\n",
    "            return [] if return_all else None\n",
    "        return candidates if return_all else candidates[0]\n",
    "    except requests.HTTPError as e:\n",
    "        # Surface the original 404/403 with a friendly hint\n",
    "        raise RuntimeError(\n",
    "            f\"Yahoo lookup failed ({e.response.status_code}). \"\n",
    "            \"Try the newer search API, ensure a real User-Agent, or check your network/proxy.\"\n",
    "        ) from e\n",
    "\n",
    "# --- Example ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(yahoo_find_ticker(\"Apple\"))            # -> {'symbol': 'AAPL', ...}\n",
    "    print(yahoo_find_ticker(\"Delta\", return_all=True)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c5bb0",
   "metadata": {},
   "source": [
    "## /src/researchers/SECresearcher.py\n",
    "Agent file to run tools in sec_tools.py for creating financial assessment based on most recent 10-K/10-Q SEC filing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any, Dict\n",
    "\n",
    "from crewai import Agent, Crew, Process, Task\n",
    "from crewai.flow.flow import Flow, and_, listen, start\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    # Import sec_tools from the tools package if available\n",
    "    from tools.sec_tools import (\n",
    "        calc_debt_to_equity,\n",
    "        calc_positive_netincome,\n",
    "        calc_profit,\n",
    "        calc_yoy_rev,\n",
    "        get_recent_facts,\n",
    "        get_risks_mna as fetch_risks_mna,\n",
    "        ticker_to_cik,\n",
    "    )\n",
    "except ImportError:\n",
    "    # Fallback import if tools is not a package\n",
    "    from researchers.tools.sec_tools import (  # type: ignore\n",
    "        calc_debt_to_equity,\n",
    "        calc_positive_netincome,\n",
    "        calc_profit,\n",
    "        calc_yoy_rev,\n",
    "        get_recent_facts,\n",
    "        get_risks_mna as fetch_risks_mna,\n",
    "        ticker_to_cik,\n",
    "    )\n",
    "\n",
    "# === Helper functions ===\n",
    "def _load_openai_client() -> OpenAI:\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "    return OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "def _safe_parse_json(raw_content: str) -> Any:\n",
    "    try:\n",
    "        return json.loads(raw_content)\n",
    "    except json.JSONDecodeError:\n",
    "        return raw_content\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# === SEC Filing Analysis Flow ===\n",
    "class SECFilingAnalysis:\n",
    "    # Initialize with OpenAI client\n",
    "    def __init__(self):\n",
    "        self.client = _load_openai_client()\n",
    "        self.state = {}\n",
    "\n",
    "    # === Public API ===\n",
    "    def run(self, ticker: str):\n",
    "        if not ticker:\n",
    "            raise ValueError(\"No ticker provided. Example: run('AAPL')\")\n",
    "\n",
    "        cik = self._get_cik(ticker)\n",
    "        facts = self._get_facts(cik)\n",
    "        financial_ratings = self._calc_financial_ratings(facts)\n",
    "        risk_mna_rating = self._get_risks_mna(cik)\n",
    "        final_report = self._get_final_report(financial_ratings, risk_mna_rating)\n",
    "\n",
    "        return {\n",
    "            \"final_result\": final_report,\n",
    "            \"financial_ratings\": financial_ratings,\n",
    "            \"risk_mna_rating\": risk_mna_rating,\n",
    "        }\n",
    "\n",
    "    # === Individual steps ===\n",
    "\n",
    "    # Get CIK from ticker\n",
    "    def _get_cik(self, ticker: str):\n",
    "        cik = ticker_to_cik(ticker)\n",
    "        if not cik:\n",
    "            raise ValueError(f\"Unable to resolve CIK for ticker '{ticker}'.\")\n",
    "        self.state[\"cik\"] = cik\n",
    "        return cik\n",
    "\n",
    "    # Get recent facts from CIK\n",
    "    def _get_facts(self, cik: str):\n",
    "        facts = get_recent_facts(cik)\n",
    "        if not facts:\n",
    "            raise ValueError(f\"No recent facts returned for CIK '{cik}'.\")\n",
    "        self.state[\"facts\"] = facts\n",
    "        return facts\n",
    "\n",
    "    # Calculate financial ratings\n",
    "    def _calc_financial_ratings(self, facts):\n",
    "        financial_ratings = {\n",
    "            \"yoy\": calc_yoy_rev(facts),\n",
    "            \"profit\": calc_profit(facts),\n",
    "            \"debt\": calc_debt_to_equity(facts),\n",
    "            \"income\": calc_positive_netincome(facts),\n",
    "        }\n",
    "        self.state[\"financial_ratings\"] = financial_ratings\n",
    "        return financial_ratings\n",
    "\n",
    "    # Get risk/MNA rating\n",
    "    def _get_risks_mna(self, cik: str):\n",
    "        risks, mna = fetch_risks_mna(cik)\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-5\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a financial analysis expert.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Provide a rating from 1 'sell', 2 'underperform', 3 'hold', \"\n",
    "                        \"4 'outperform', 5 'strong buy' for the following based on risk factors: \"\n",
    "                        f\"{risks} and management discussion and analysis: {mna}. \"\n",
    "                        \"Respond with JSON only like {'rating': 4, 'rationale': 'text'}.\"\n",
    "                    ),\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        parsed_rating = _safe_parse_json(response.choices[0].message.content)\n",
    "        self.state[\"risk_mna_rating\"] = parsed_rating\n",
    "        return parsed_rating\n",
    "\n",
    "    # Get final report\n",
    "    def _get_final_report(self, financial_ratings, risk_mna_rating):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-5\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a financial analysis expert.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Provide a rating from 1 'sell', 2 'underperform', 3 'hold', \"\n",
    "                        \"4 'outperform', 5 'strong buy' based on the following context. \"\n",
    "                        f\"Financial ratings: {financial_ratings}. \"\n",
    "                        f\"Risk/MNA rating: {risk_mna_rating}. \"\n",
    "                        \"Respond with JSON only like {'rating': 4, 'rationale': 'text'}. \"\n",
    "                        \"Give 20% weight for YoY, 20% for profit, 15% for debt, \"\n",
    "                        \"15% for income, 30% for risk/mna.\"\n",
    "                    ),\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        final_result = _safe_parse_json(response.choices[0].message.content)\n",
    "        return final_result\n",
    "\n",
    "# run SEC Filing Analysis as an Agent\n",
    "def run_sec_filing_agent(inputs: dict):\n",
    "    ticker = inputs.get(\"ticker\")\n",
    "    analyzer = SECFilingAnalysis()\n",
    "    result = analyzer.run(ticker)\n",
    "    return result\n",
    "\n",
    "# Define the SEC Filing Agent\n",
    "sec_filing_agent = Agent(\n",
    "    role=\"Flow Runner\",\n",
    "    goal=\"Run the SEC filing analysis and return raw output\",\n",
    "    name=\"SEC Filing Agent\",\n",
    "    description=\"Executes SEC analysis and returns unmodified JSON\",\n",
    "    backstory=\"This agent runs the SEC filing analysis flow and returns the results as-is.\",\n",
    "    expected_output=\"Full JSON returned from sec_filing_flow, do not modify.\",\n",
    "    model=\"gpt-5-mini\",\n",
    "    run_function=run_sec_filing_agent,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(run_sec_filing_agent({\"ticker\": \"AAPL\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70790bb",
   "metadata": {},
   "source": [
    "## /src/researchers/tools/sec_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd439ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from pathlib import Path\n",
    "from sec_cik_mapper import StockMapper\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def ticker_to_cik(ticker: str) -> str:\n",
    "    mapper = StockMapper()\n",
    "    if ticker.upper() in mapper.ticker_to_cik:\n",
    "        print(f\"Ticker {ticker} CIK={mapper.ticker_to_cik[ticker]}\")\n",
    "        CIK = mapper.ticker_to_cik[ticker]\n",
    "    else:\n",
    "        print(f\"Ticker {ticker} not found\")\n",
    "    return CIK\n",
    "\n",
    "def get_recent_facts(CIK: str):\n",
    "    \"\"\"\n",
    "    Fetches the most recent 10-Q or 10-K filing facts from SEC's companyfacts API.\n",
    "    Returns a list of fact entries (concept, unit, value, end_date).\n",
    "    \"\"\"\n",
    "    # 1. Configuration\n",
    "    URL = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{CIK.zfill(10)}.json\"\n",
    "    USER_AGENT = \"Your Name (your.email@example.com)\"  # <-- REQUIRED by SEC\n",
    "\n",
    "    # 2. Fetch Data\n",
    "    try:\n",
    "        headers = {\"User-Agent\": USER_AGENT}\n",
    "        response = requests.get(URL, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"[Error] Could not fetch data for CIK {CIK}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 3. Identify the most recent 10-Q or 10-K accession number\n",
    "    latest_filing_accn = None\n",
    "    latest_filed_date = datetime.min\n",
    "    latest_form = None\n",
    "\n",
    "    facts = data.get(\"facts\", {}).get(\"us-gaap\", {})\n",
    "\n",
    "    for concept in facts.values():\n",
    "        if \"units\" not in concept:\n",
    "            continue\n",
    "        for unit_facts in concept[\"units\"].values():\n",
    "            for fact in unit_facts:\n",
    "                form = fact.get(\"form\", \"\")\n",
    "                # Skip other forms not 10-Q or 10-K\n",
    "                if form not in (\"10-Q\", \"10-K\"):\n",
    "                    continue\n",
    "\n",
    "                filed_date_str = fact.get(\"filed\")\n",
    "                if not filed_date_str:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    filed_date = datetime.strptime(filed_date_str, \"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "                if filed_date > latest_filed_date:\n",
    "                    latest_filed_date = filed_date\n",
    "                    latest_filing_accn = fact.get(\"accn\")\n",
    "                    latest_form = form\n",
    "\n",
    "    if not latest_filing_accn:\n",
    "        print(f\"[Warning] No 10-Q or 10-K filings found for CIK {CIK}.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Most recent filing for CIK {CIK}: Form {latest_form}, Accession {latest_filing_accn}, Filed on {latest_filed_date.date()}\")\n",
    "\n",
    "    # 4. Extract all facts from the most recent filing\n",
    "    most_recent_facts = []\n",
    "    for concept_name, concept in facts.items():\n",
    "        if \"units\" not in concept:\n",
    "            continue\n",
    "        for unit_name, unit_facts in concept[\"units\"].items():\n",
    "            for fact in unit_facts:\n",
    "                if fact.get(\"accn\") == latest_filing_accn:\n",
    "                    most_recent_facts.append({\n",
    "                        \"concept\": concept_name,\n",
    "                        \"unit\": unit_name,\n",
    "                        \"value\": fact.get(\"val\"),\n",
    "                        \"end_date\": fact.get(\"end\"),\n",
    "                        \"form\": fact.get(\"form\"),\n",
    "                        \"accn\": fact.get(\"accn\")\n",
    "                    })\n",
    "    return most_recent_facts\n",
    "\n",
    "# Calculate year-over-year revenue growth\n",
    "def calc_yoy_rev(facts):\n",
    "    # Filter the data for total revenue\n",
    "    revenue_data = [item for item in facts if item['concept'].lower()[:7] == 'revenue']\n",
    "\n",
    "    curr_end = max([item['end_date'] for item in revenue_data])\n",
    "    prev_end = min([item['end_date'] for item in revenue_data])\n",
    "\n",
    "    # Sum the quarterly values by year\n",
    "    revenue_prev = sum(item['value'] for item in revenue_data if item['end_date'] == prev_end)\n",
    "    revenue_curr = sum(item['value'] for item in revenue_data if item['end_date'] == curr_end)\n",
    "\n",
    "    # Calculate the YoY growth\n",
    "    if revenue_prev > 0:\n",
    "        yoy_growth = ((revenue_curr - revenue_prev) / revenue_prev) * 100\n",
    "    else:\n",
    "        yoy_growth = float('inf') if revenue_curr > 0 else 0\n",
    "\n",
    "    # # Print the results\n",
    "    # print(f\"Total Revenue for 2024: ${revenue_prev:,}\")\n",
    "    # print(f\"Total Revenue for 2025: ${revenue_curr:,}\")\n",
    "    # print(f\"Year-over-Year Revenue Growth: {yoy_growth:.2f}%\")\n",
    "\n",
    "    # 5 if greater than 15, 1 if less than 5, sliding scale between\n",
    "    if yoy_growth > 15:\n",
    "        return_val = 5\n",
    "    elif yoy_growth < 5:\n",
    "        return_val = 1\n",
    "    else:\n",
    "        return_val = yoy_growth / 5\n",
    "\n",
    "    return {'yoy_growth': yoy_growth, 'ratintg': return_val, 'description' : \"Year over year revenue growth as a percentage\"}\n",
    "\n",
    "# Calculate profit percent\n",
    "def calc_profit(facts):\n",
    "    revenue_data = [item for item in facts if item['concept'].lower()[:7] == 'revenue']\n",
    "    curr_end = max([item['end_date'] for item in revenue_data])\n",
    "    revenue_curr = sum(item['value'] for item in revenue_data if item['end_date'] == curr_end)\n",
    "\n",
    "    profit_data = [item for item in facts if 'netincome' in item['concept'].lower()]\n",
    "    curr_end = max([item['end_date'] for item in profit_data])\n",
    "\n",
    "    # Sum the quarterly values by year\n",
    "    net_income = sum(item['value'] for item in profit_data if item['end_date'] == curr_end)\n",
    "\n",
    "    # print(f\"{net_income:,} {revenue_curr:,}\")\n",
    "\n",
    "    net_profit_margin = (net_income / revenue_curr) * 100\n",
    "\n",
    "    # print(net_profit_margin)\n",
    "\n",
    "    if net_profit_margin > 10:\n",
    "        return_val = 5\n",
    "    elif net_profit_margin < 5:\n",
    "        return_val = 1\n",
    "    else:\n",
    "        return_val = net_profit_margin / 5\n",
    "\n",
    "    # print(f\"{return_val:.2f}\")\n",
    "    return {'net_profit_margin': net_profit_margin, 'rating': return_val, 'description': \"Net profit margin as a percentage\"}\n",
    "\n",
    "# Calculate debt to equity ratio\n",
    "def calc_debt_to_equity(facts):\n",
    "    total_debt = 0\n",
    "\n",
    "    for item_name in ['LongTermDebtNoncurrent', 'LongTermDebtCurrent', 'ShortTermBorrowings']:\n",
    "        debt_data = [item for item in facts if (item_name.lower() in item['concept'].lower())]\n",
    "        if debt_data:\n",
    "            curr_end = max([item['end_date'] for item in debt_data])\n",
    "            debt_data = [item for item in facts if (item_name.lower() in item['concept'].lower()) and (item['end_date'] == curr_end)]\n",
    "\n",
    "        if len(debt_data) == 1:\n",
    "            debt_item = debt_data[0]['value']\n",
    "        else:\n",
    "            debt_item = 0\n",
    "        total_debt += debt_item\n",
    "\n",
    "    # print(total_debt)\n",
    "\n",
    "    se_data = [item for item in facts if ('StockholdersEquity'.lower() == item['concept'].lower()) and (item['end_date'] == curr_end)]\n",
    "    curr_end = max([item['end_date'] for item in se_data])\n",
    "    se_data = [item for item in facts if ('StockholdersEquity'.lower() == item['concept'].lower()) and (item['end_date'] == curr_end)]\n",
    "\n",
    "    if len(se_data) == 1:\n",
    "        se = se_data[0]['value']\n",
    "    else:\n",
    "        se = 0\n",
    "\n",
    "    debt_to_equity = total_debt / se\n",
    "\n",
    "    #print(se)\n",
    "\n",
    "    if debt_to_equity < 0.5:\n",
    "        return_val = 5\n",
    "    elif debt_to_equity > 1:\n",
    "        return_val = 1\n",
    "    else:\n",
    "        return_val = (-8 * debt_to_equity) + 9\n",
    "\n",
    "    # print(f\"D_E={debt_to_equity} {return_val}\")\n",
    "    return {'debt_to_equity': debt_to_equity, 'rating': return_val, 'description': \"Debt to equity ratio\"}\n",
    "\n",
    "# Calculate if net income is positive\n",
    "def calc_positive_netincome(facts):\n",
    "    for item_name in ['NetIncomeLoss']:\n",
    "        \n",
    "        cash_data = [item for item in facts if (item_name.lower() in item['concept'].lower())]\n",
    "\n",
    "        curr_end = max([item['end_date'] for item in cash_data])\n",
    "\n",
    "        net_income = sum(item['value'] for item in cash_data if item['end_date'] == curr_end)\n",
    "\n",
    "        if net_income == None:\n",
    "            net_income = 0\n",
    "\n",
    "    if net_income > 0:\n",
    "        return_val = 5\n",
    "    elif net_income < 0:\n",
    "        return_val = 1\n",
    "    else:\n",
    "        return_val = 3\n",
    "\n",
    "    # print(net_income, return_val)\n",
    "    return {'net_income': net_income, 'rating': return_val, 'description': \"Positive net income\"}\n",
    "\n",
    "def get_latest_10k_text_url(cik: str, user_agent: str):\n",
    "    # Step 1: fetch the submissions JSON\n",
    "    padded = cik.zfill(10)\n",
    "    submissions_url = f\"https://data.sec.gov/submissions/CIK{padded}.json\"\n",
    "    headers = {\"User-Agent\": user_agent}\n",
    "    resp = requests.get(submissions_url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    \n",
    "    # Step 2: find the latest 10-K filing metadata\n",
    "    filings = pd.DataFrame(data['filings']['recent'])\n",
    "    # filter by form ‚Äú10-K‚Äù (not ‚Äú10-K/A‚Äù) ‚Äî you might adapt that logic\n",
    "    tenk_rows = filings[filings['form'] == '10-K']\n",
    "    if tenk_rows.empty:\n",
    "        raise ValueError(\"No 10-K filings found for this CIK\")\n",
    "    latest = tenk_rows.iloc[0]\n",
    "    accession = latest['accessionNumber']\n",
    "    primary_doc = latest['primaryDocument']\n",
    "    \n",
    "    # Step 3: build paths\n",
    "    accession_nodash = accession.replace('-', '')\n",
    "    cik_int = int(cik)  # for path part\n",
    "    base = f\"https://www.sec.gov/Archives/edgar/data/{cik_int}/{accession_nodash}/\"\n",
    "    \n",
    "    # The HTML or .htm version:\n",
    "    html_url = base + primary_doc\n",
    "    \n",
    "    # The .txt submission file often follows:\n",
    "    # example: ‚ÄúCIK-yy-nnnnn.txt‚Äù\n",
    "    # we can infer its name ‚Äî sometimes the name is the same as `primaryDocument` but with `.txt`\n",
    "    # common pattern: <cik>-<two digit year>-<5 digit seq>.txt\n",
    "    # The JSON ‚ÄúaccessionNumber‚Äù is like ‚Äú0000320193-24-000123‚Äù\n",
    "    # So txt filename might be ‚Äú0000320193-24-000123.txt‚Äù\n",
    "    txt_filename = f\"{accession}.txt\"\n",
    "    txt_url = base + txt_filename\n",
    "    \n",
    "    return {\n",
    "        \"html_url\": html_url,\n",
    "        \"txt_url\": txt_url,\n",
    "        \"accession\": accession,\n",
    "        \"primary_document\": primary_doc\n",
    "    }\n",
    "\n",
    "# Get risks and MNA from most recent 10-K since these are often not listed in 10-Q\n",
    "def get_risks_mna(CIK: str):\n",
    "    txt_url = get_latest_10k_text_url(cik=CIK, user_agent=\"Your Name (your.email@example.com)\")[\"txt_url\"]\n",
    "    headers = {\"User-Agent\": \"Your Name (your.email@example.com)\"}\n",
    "\n",
    "    #print(txt_url)\n",
    "\n",
    "    # Step 4: Download and extract Risk Factors section\n",
    "    txt = requests.get(txt_url, headers=headers).text\n",
    "\n",
    "    soup = BeautifulSoup(txt, \"html.parser\")\n",
    "    clean_text = soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "    # Pattern for locating \"Item 1A ‚Äì Risk Factors\" and its next section start\n",
    "    pattern_risk_start = re.compile(\n",
    "        r\"(?i)item\\s*1A\\.[^a-zA-Z0-9]{0,10}\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    pattern_next_section = re.compile(\n",
    "        r\"(?is)item\\s*(1B|2)[^a-zA-Z0-9]{0,10}\"\n",
    "    )\n",
    "\n",
    "    # Find all matches (returns Match objects)\n",
    "    matches_1a = list(pattern_risk_start.finditer(clean_text))\n",
    "    matches_1b2 = list(pattern_next_section.finditer(clean_text))\n",
    "\n",
    "    match_1a_list = []\n",
    "    match_1b2_list = []\n",
    "\n",
    "    if matches_1a:\n",
    "        for i, match in enumerate(matches_1a, start=1):\n",
    "            match_1a_list.append(match.start())\n",
    "    else:\n",
    "        print(\"No Item 1A ‚Äì Risk Factors occurrences found.\")\n",
    "\n",
    "    if matches_1b2:\n",
    "        for i, match in enumerate(matches_1b2, start=1):\n",
    "            match_1b2_list.append(match.start())\n",
    "    else:\n",
    "        print(\"No Item 1B or Item 2 occurrences found.\")\n",
    "\n",
    "    # print(match_1a_list)\n",
    "    # print(match_1b2_list)\n",
    "\n",
    "    start_pos = match_1a_list[1]\n",
    "\n",
    "    for item_pos in match_1b2_list:\n",
    "        if item_pos > start_pos:\n",
    "            end_pos = item_pos\n",
    "            break\n",
    "\n",
    "    # print(start_pos, end_pos)\n",
    "\n",
    "    risk_text = clean_text[start_pos:end_pos]\n",
    "\n",
    "    # Pattern for locating \"Item 7\" and its next section start\n",
    "    pattern_risk_start = re.compile(\n",
    "        r\"(?i)item\\s*7\\.[^a-zA-Z0-9]{0,10}\"\n",
    "    )\n",
    "    pattern_next_section = re.compile(\n",
    "        r\"(?is)item\\s*8\\.[^a-zA-Z0-9]{0,10}\"\n",
    "    )\n",
    "\n",
    "    matches_7 = list(pattern_risk_start.finditer(clean_text))\n",
    "    matches_8 = list(pattern_next_section.finditer(clean_text))\n",
    "\n",
    "    match_7_list = []\n",
    "    match_8_list = []\n",
    "\n",
    "    if matches_7:\n",
    "        for i, match in enumerate(matches_1a, start=1):\n",
    "            match_7_list.append(match.start())\n",
    "    else:\n",
    "        print(\"No Item 7 occurrences found.\")\n",
    "\n",
    "    if matches_8:\n",
    "        for i, match in enumerate(matches_8, start=1):\n",
    "            match_8_list.append(match.start())\n",
    "    else:\n",
    "        print(\"No Item 8 occurrences found.\")\n",
    "\n",
    "    start_pos = match_7_list[1]\n",
    "\n",
    "    for item_pos in match_8_list:\n",
    "        if item_pos > start_pos:\n",
    "            end_pos = item_pos\n",
    "            break\n",
    "\n",
    "    # print(start_pos, end_pos)\n",
    "\n",
    "    mda_text = clean_text[start_pos:end_pos]\n",
    "    return risk_text, mda_text\n",
    "\n",
    "# This function was used in development but is not currently called in the flow, left for debugging\n",
    "def prompt(risk_text: str, mda_text: str):\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a financial analysis expert.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Provide a rating from 1 'sell', 2 'underperform', 3 'hold', 4 'outperform', 5 'strong buy' for the following based on risk factors: {risk_text} and management discussion and analysis: {mda_text}. Respond with json only like {{'rating': 4, 'rationale': 'text'}}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# This function was used in development but is not currently called in the flow, left for debugging\n",
    "def final_rating(risk_rating, yoy_rating, profit_rating, debt_equity_rating, net_income_rating):\n",
    "    # Set weights for calculation\n",
    "    weights = {\n",
    "        'risk': 0.3,\n",
    "        'yoy': 0.2,\n",
    "        'profit': 0.2,\n",
    "        'debt_equity': 0.15,\n",
    "        'net_income': 0.15\n",
    "    }\n",
    "    \n",
    "    # Calculate final score with weights\n",
    "    final_score = (\n",
    "        risk_rating * weights['risk'] +\n",
    "        yoy_rating * weights['yoy'] +\n",
    "        profit_rating * weights['profit'] +\n",
    "        debt_equity_rating * weights['debt_equity'] +\n",
    "        net_income_rating * weights['net_income']\n",
    "    )\n",
    "    \n",
    "    # Determine recommendation based on final score\n",
    "    if final_score >= 4:\n",
    "        recommendation = 'strong buy'\n",
    "    elif final_score >= 3.5:\n",
    "        recommendation = 'outperform'\n",
    "    elif final_score >= 2.5:\n",
    "        recommendation = 'hold'\n",
    "    elif final_score >= 1.5:\n",
    "        recommendation = 'underperform'\n",
    "    else:\n",
    "        recommendation = 'sell'\n",
    "    \n",
    "    return final_score, recommendation\n",
    "\n",
    "def main(ticker: str):\n",
    "    CIK = ticker_to_cik(ticker)\n",
    "    if CIK is None:\n",
    "        print(f\"Could not find CIK for ticker {ticker}. Exiting.\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"Using CIK {CIK} for ticker {ticker}\")\n",
    "\n",
    "    facts = get_recent_facts(CIK)\n",
    "    yoy_rating = calc_yoy_rev(facts)\n",
    "    profit_rating = calc_profit(facts)\n",
    "    debt_equity_rating = calc_debt_to_equity(facts)\n",
    "    net_income_rating = calc_positive_netincome(facts)\n",
    "\n",
    "    risk_text, mda_text = get_risks_mna(CIK)\n",
    "    risk_dict = json.loads(prompt(risk_text, mda_text))\n",
    "\n",
    "    risk_rating = risk_dict['rating']\n",
    "\n",
    "    final_score, recommendation = final_rating(\n",
    "        risk_rating,\n",
    "        yoy_rating,\n",
    "        profit_rating,\n",
    "        debt_equity_rating,\n",
    "        net_income_rating\n",
    "    )\n",
    "    print(f\"rating {final_score}, recommendation: {recommendation} rationale: {risk_dict['rationale']}\")\n",
    "    return({'rating': final_score, 'recommendation': recommendation})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ff9fdd",
   "metadata": {},
   "source": [
    "## /src/researchers/YahooFinanceCrew.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6be821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YahooFinanceAgent v2 \n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser as date_parser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# optional technical indicators library\n",
    "try:\n",
    "    from ta.momentum import RSIIndicator\n",
    "except Exception:\n",
    "    RSIIndicator = None\n",
    "\n",
    "# Simple in-memory cache for fetched data\n",
    "_YF_CACHE = {}\n",
    "def _cache_get(key):\n",
    "    v = _YF_CACHE.get(key)\n",
    "    if v and (time.time() - v[\"ts\"]) < 300:\n",
    "        return v[\"value\"]\n",
    "    return None\n",
    "\n",
    "# set cache value\n",
    "def _cache_set(key, value):\n",
    "    _YF_CACHE[key] = {\"ts\": time.time(), \"value\": value}\n",
    "\n",
    "# Yahoo Finance Analysis Agent\n",
    "class YahooFinanceAgent:\n",
    "    SOURCE = \"YahooFinanceAgent\"\n",
    "    # Initialize agent\n",
    "    def __init__(self, session_name=None):\n",
    "        self.session_name = session_name or \"default\"\n",
    "\n",
    "    # Fetch price history from Yahoo Finance\n",
    "    def _fetch_price_history(self, symbol, period_days=365):\n",
    "        key = f\"prices::{symbol}::{period_days}\"\n",
    "        cached = _cache_get(key)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "        end = datetime.now().date()\n",
    "        start = end - timedelta(days=period_days + 7)\n",
    "        # set auto_adjust explicitly to avoid FutureWarning\n",
    "        df = yf.download(symbol, start=start.isoformat(), end=end.isoformat(),\n",
    "                         progress=False, threads=False, auto_adjust=True)\n",
    "        if df is None or df.empty:\n",
    "            raise ValueError(f\"No price data fetched for {symbol}\")\n",
    "        df = df.reset_index().rename(columns={\"Date\": \"date\"})\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        _cache_set(key, df)\n",
    "        return df\n",
    "    # Fetch ticker object from yfinance\n",
    "    def _fetch_ticker(self, symbol):\n",
    "        key = f\"ticker::{symbol}\"\n",
    "        cached = _cache_get(key)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "        t = yf.Ticker(symbol)\n",
    "        _cache_set(key, t)\n",
    "        return t\n",
    "\n",
    "    # Safe attribute getter\n",
    "    def _safe_get(self, obj, attr, default=None):\n",
    "        try:\n",
    "            return getattr(obj, attr, default) if obj is not None else default\n",
    "        except Exception:\n",
    "            return default\n",
    "\n",
    "    # Compute technical indicators from price DataFrame\n",
    "    def _compute_indicators(self, price_df):\n",
    "        out = {}\n",
    "        # Ensure DataFrame and locate Close column whether columns are single-level or multi-level\n",
    "        df = price_df.copy().set_index(\"date\").sort_index()\n",
    "        cols = df.columns\n",
    "        # detect MultiIndex columns like ('Close','AAPL') or single-level 'Close'\n",
    "        if isinstance(cols, pd.MultiIndex):\n",
    "            # find first level name 'Close' (case-sensitive)\n",
    "            close_cols = [c for c in cols if c[0] == \"Close\"]\n",
    "            if not close_cols:\n",
    "                raise ValueError(\"Price DataFrame missing 'Close' column (multiindex)\")\n",
    "            close_series = df[close_cols[0]]\n",
    "        else:\n",
    "            if \"Close\" not in df.columns:\n",
    "                # try lowercase fallback\n",
    "                low = [c for c in df.columns if str(c).lower() == \"close\"]\n",
    "                if not low:\n",
    "                    raise ValueError(\"Price DataFrame missing 'Close' column\")\n",
    "                close_series = df[low[0]]\n",
    "            else:\n",
    "                close_series = df[\"Close\"]\n",
    "    \n",
    "        # convert to numeric 1-D array and drop NaNs\n",
    "        close_vals = pd.to_numeric(close_series, errors=\"coerce\").to_numpy()\n",
    "        # if close_series came from a DataFrame column (multiindex extraction) it may be 2-D; ensure 1-D\n",
    "        if close_vals.ndim > 1:\n",
    "            # if shape (n,1) flatten\n",
    "            close_vals = close_vals.reshape(-1)\n",
    "        mask = ~np.isnan(close_vals)\n",
    "        close_vals = close_vals[mask]\n",
    "        n = len(close_vals)\n",
    "        if n == 0:\n",
    "            raise ValueError(\"Empty close series after cleaning\")\n",
    "    \n",
    "        # scalar-safe access using numpy indices\n",
    "        latest = float(close_vals[-1])\n",
    "        out[\"latest_close\"] = latest\n",
    "    \n",
    "        # first/last dates from df index (after cleaning mask we approximate using original index)\n",
    "        try:\n",
    "            out[\"first_date\"] = df.index[0].isoformat()\n",
    "            out[\"last_date\"] = df.index[-1].isoformat()\n",
    "        except Exception:\n",
    "            out[\"first_date\"] = None\n",
    "            out[\"last_date\"] = None\n",
    "    \n",
    "        def pct_by_indices(latest_idx, prior_idx):\n",
    "            if prior_idx < 0 or latest_idx < 0 or prior_idx >= n or latest_idx >= n:\n",
    "                return None\n",
    "            prior = close_vals[prior_idx]\n",
    "            latest_v = close_vals[latest_idx]\n",
    "            if prior == 0:\n",
    "                return None\n",
    "            return float((latest_v / prior) - 1)\n",
    "    \n",
    "        # Calculate returns over various periods\n",
    "        out[\"7d_return\"] = pct_by_indices(n - 1, n - 8) if n >= 8 else None\n",
    "        out[\"30d_return\"] = pct_by_indices(n - 1, n - 31) if n >= 31 else None\n",
    "        out[\"90d_return\"] = pct_by_indices(n - 1, n - 91) if n >= 91 else None\n",
    "        out[\"1y_return\"] = pct_by_indices(n - 1, 0) if n >= 252 else None\n",
    "    \n",
    "        # Use pandas Series built from the cleaned numpy array for rolling ops\n",
    "        close_series_clean = pd.Series(close_vals)\n",
    "    \n",
    "        # Simple Moving Averages and related indicators\n",
    "        out[\"sma_20\"] = float(close_series_clean.rolling(window=20, min_periods=1).mean().iat[-1])\n",
    "        out[\"sma_50\"] = float(close_series_clean.rolling(window=50, min_periods=1).mean().iat[-1])\n",
    "        out[\"sma_200\"] = float(close_series_clean.rolling(window=200, min_periods=1).mean().iat[-1])\n",
    "        out[\"price_vs_sma20\"] = 1 if out[\"latest_close\"] > out[\"sma_20\"] else -1\n",
    "        out[\"volatility_30d\"] = float(close_series_clean.pct_change().rolling(window=21, min_periods=1).std().iat[-1])\n",
    "    \n",
    "        # max drawdown\n",
    "        roll_max = close_series_clean.cummax()\n",
    "        drawdown = (close_series_clean - roll_max) / roll_max\n",
    "        out[\"max_drawdown\"] = float(drawdown.min())\n",
    "    \n",
    "        # RSI 14 (safe fallback if ta not installed)\n",
    "        try:\n",
    "            if RSIIndicator is not None:\n",
    "                rsi = RSIIndicator(close_series_clean, window=14)\n",
    "                out[\"rsi_14\"] = float(rsi.rsi().iat[-1])\n",
    "            else:\n",
    "                delta = close_series_clean.diff().dropna()\n",
    "                up = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "                down = -delta.where(delta < 0, 0).rolling(14).mean()\n",
    "                rs = up / down.replace(0, np.nan)\n",
    "                last_rs = rs.iat[-1] if len(rs) > 0 else np.nan\n",
    "                out[\"rsi_14\"] = float(100 - (100 / (1 + last_rs))) if not np.isnan(last_rs) else None\n",
    "        except Exception:\n",
    "            out[\"rsi_14\"] = None\n",
    "    \n",
    "        return out\n",
    "\n",
    "    # Fetch fundamental data from ticker object\n",
    "    def _fetch_fundamentals(self, ticker_obj):\n",
    "        out = {}\n",
    "        try:\n",
    "            info = ticker_obj.info or {}\n",
    "        except Exception:\n",
    "            info = {}\n",
    "        # common fields, may be missing\n",
    "        out[\"market_cap\"] = info.get(\"marketCap\")\n",
    "        out[\"trailing_pe\"] = info.get(\"trailingPE\")\n",
    "        out[\"forward_pe\"] = info.get(\"forwardPE\")\n",
    "        out[\"peg_ratio\"] = info.get(\"pegRatio\")\n",
    "        out[\"beta\"] = info.get(\"beta\")\n",
    "        return out\n",
    "\n",
    "    # Compute returns around last earnings event\n",
    "    def _earnings_event_returns(self, ticker_obj, price_df):\n",
    "        # attempt to fetch last earnings calendar and compute 7d pre/post returns around the last earnings date\n",
    "        try:\n",
    "            cal = ticker_obj.calendar\n",
    "            # calendar may have nextEarningsDate etc; fallback to earnings_dates from history if available\n",
    "            earnings = ticker_obj.get_earnings_dates(limit=5) if hasattr(ticker_obj, \"get_earnings_dates\") else None\n",
    "        except Exception:\n",
    "            earnings = None\n",
    "        # fallback: attempt to read earnings from history property\n",
    "        if earnings is None:\n",
    "            try:\n",
    "                eht = ticker_obj.earnings_dates if hasattr(ticker_obj, \"earnings_dates\") else None\n",
    "                earnings = eht\n",
    "            except Exception:\n",
    "                earnings = None\n",
    "        # convert to list of datetimes if possible\n",
    "        event = None\n",
    "        if isinstance(earnings, (list, tuple)) and len(earnings) > 0:\n",
    "            # expect list of dicts with 'Earnings Date' or 'startdatetime'\n",
    "            for e in earnings:\n",
    "                if isinstance(e, dict) and (\"startdatetime\" in e or \"Earnings Date\" in e or \"date\" in e):\n",
    "                    try:\n",
    "                        # try many keys\n",
    "                        d = e.get(\"startdatetime\") or e.get(\"Earnings Date\") or e.get(\"date\")\n",
    "                        event = date_parser.parse(d) if isinstance(d, str) else d\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        # as very last resort, try ticker.calendar nextEarningsDate\n",
    "        if event is None:\n",
    "            try:\n",
    "                cal = ticker_obj.calendar\n",
    "                if isinstance(cal, pd.DataFrame) and \"Earnings Date\" in cal.index:\n",
    "                    event = cal.loc[\"Earnings Date\"].values[0]\n",
    "            except Exception:\n",
    "                event = None\n",
    "        # compute returns if we have event and prices\n",
    "        if event is None:\n",
    "            return {\"last_earnings_date\": None, \"pre7_return\": None, \"post7_return\": None}\n",
    "        event_date = pd.to_datetime(event).date()\n",
    "        df = price_df.copy().set_index(\"date\").sort_index()\n",
    "        try:\n",
    "            # compute pre and post 7-day returns\n",
    "            pre_start = event_date - timedelta(days=10)\n",
    "            pre_end = event_date - timedelta(days=1)\n",
    "            post_start = event_date + timedelta(days=1)\n",
    "            post_end = event_date + timedelta(days=10)\n",
    "            pre = df.loc[(df.index.date >= pre_start) & (df.index.date <= pre_end)][\"Close\"]\n",
    "            post = df.loc[(df.index.date >= post_start) & (df.index.date <= post_end)][\"Close\"]\n",
    "            pre7 = float((pre.iloc[-1] / pre.iloc[0]) - 1) if len(pre) >= 2 else None\n",
    "            post7 = float((post.iloc[-1] / post.iloc[0]) - 1) if len(post) >= 2 else None\n",
    "            return {\"last_earnings_date\": event_date.isoformat(), \"pre7_return\": pre7, \"post7_return\": post7}\n",
    "        except Exception:\n",
    "            return {\"last_earnings_date\": event_date.isoformat(), \"pre7_return\": None, \"post7_return\": None}\n",
    "\n",
    "    # Score and confidence calculation\n",
    "    def _score_and_confidence(self, indicators, fundamentals, earnings_event):\n",
    "        # Base score 3 neutral\n",
    "        score = 3.0\n",
    "        confidence = 0.5\n",
    "        evidence = []\n",
    "\n",
    "        # Momentum: 30d and 90d\n",
    "        r30 = indicators.get(\"30d_return\")\n",
    "        r90 = indicators.get(\"90d_return\")\n",
    "        if r30 is not None:\n",
    "            if r30 > 0.08:\n",
    "                score += 0.8; confidence += 0.08; evidence.append(\"strong_30d_momentum\")\n",
    "            elif r30 > 0.02:\n",
    "                score += 0.35; confidence += 0.04; evidence.append(\"mild_30d_momentum\")\n",
    "            elif r30 < -0.08:\n",
    "                score -= 0.9; confidence += 0.07; evidence.append(\"strong_30d_down\")\n",
    "            elif r30 < -0.02:\n",
    "                score -= 0.35; confidence += 0.03; evidence.append(\"mild_30d_down\")\n",
    "        if r90 is not None and r90 > 0.20:\n",
    "            score += 0.4; confidence += 0.03; evidence.append(\"90d_strong_up\")\n",
    "\n",
    "        # SMA position\n",
    "        if indicators.get(\"price_vs_sma20\") == 1:\n",
    "            score += 0.25; confidence += 0.03; evidence.append(\"above_sma20\")\n",
    "        else:\n",
    "            score -= 0.15; confidence += 0.02; evidence.append(\"below_sma20\")\n",
    "\n",
    "        # Fundamentals\n",
    "        pe = fundamentals.get(\"trailing_pe\")\n",
    "        fpe = fundamentals.get(\"forward_pe\")\n",
    "        peg = fundamentals.get(\"peg_ratio\")\n",
    "        if pe:\n",
    "            if pe < 10:\n",
    "                score += 0.4; confidence += 0.03; evidence.append(\"cheap_pe\")\n",
    "            elif pe > 60:\n",
    "                score -= 0.5; confidence += 0.03; evidence.append(\"high_pe\")\n",
    "        if peg and peg < 1:\n",
    "            score += 0.25; confidence += 0.02; evidence.append(\"low_peg\")\n",
    "\n",
    "        # Earnings event behavior\n",
    "        post = earnings_event.get(\"post7_return\")\n",
    "        if post is not None:\n",
    "            if post > 0.05:\n",
    "                score += 0.4; confidence += 0.04; evidence.append(\"earnings_post_positive\")\n",
    "            elif post < -0.05:\n",
    "                score -= 0.6; confidence += 0.05; evidence.append(\"earnings_post_negative\")\n",
    "\n",
    "        # Volatility impact on confidence\n",
    "        vol = indicators.get(\"volatility_30d\") or 0.0\n",
    "        if vol > 0.06:\n",
    "            confidence -= 0.12; evidence.append(\"high_volatility\")\n",
    "        elif vol < 0.02:\n",
    "            confidence += 0.04; evidence.append(\"low_volatility\")\n",
    "\n",
    "        # RSI extreme adjustments\n",
    "        rsi = indicators.get(\"rsi_14\")\n",
    "        if rsi is not None:\n",
    "            if rsi > 75:\n",
    "                score -= 0.25; evidence.append(\"rsi_overbought\")\n",
    "            elif rsi < 25:\n",
    "                score += 0.25; evidence.append(\"rsi_oversold\")\n",
    "\n",
    "        # Data availability boosts confidence\n",
    "        if fundamentals.get(\"market_cap\"):\n",
    "            confidence += 0.03\n",
    "        if indicators.get(\"1y_return\") is not None:\n",
    "            confidence += 0.02\n",
    "\n",
    "        # clamp and convert\n",
    "        confidence = max(0.0, min(1.0, confidence))\n",
    "        score = max(1.0, min(5.0, score))\n",
    "        rating = int(round(score))\n",
    "        rating = max(1, min(5, rating))\n",
    "        return rating, float(confidence), evidence\n",
    "\n",
    "    def analyze(self, symbol, period_days=365):\n",
    "        #start_ts = datetime.utcnow()\n",
    "        start_ts = datetime.now()\n",
    "        try:\n",
    "            prices = self._fetch_price_history(symbol, period_days)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"symbol\": symbol,\n",
    "                \"rating\": 3,\n",
    "                \"confidence\": 0.12,\n",
    "                #\"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "                \"timestamp\": start_ts.isoformat() + \"Z\",\n",
    "                \"source\": self.SOURCE,\n",
    "                \"context\": {\"error\": f\"price_fetch_failed: {str(e)}\"}\n",
    "            }\n",
    "\n",
    "        # Gather data\n",
    "        ticker = self._fetch_ticker(symbol)\n",
    "        indicators = self._compute_indicators(prices)\n",
    "        fundamentals = self._fetch_fundamentals(ticker)\n",
    "        earnings_event = self._earnings_event_returns(ticker, prices)\n",
    "        rating, confidence, evidence = self._score_and_confidence(indicators, fundamentals, earnings_event)\n",
    "\n",
    "        # Create rationale\n",
    "        rationale = []\n",
    "        if evidence:\n",
    "            rationale.append(\" ; \".join(evidence))\n",
    "        if fundamentals.get(\"trailing_pe\") is not None:\n",
    "            rationale.append(f\"pe={fundamentals.get('trailing_pe')}\")\n",
    "        if earnings_event.get(\"post7_return\") is not None:\n",
    "            rationale.append(f\"earn_post7={earnings_event.get('post7_return'):.3f}\")\n",
    "\n",
    "        # Create context fopr payload\n",
    "        context = {\n",
    "            \"key_indicators\": indicators,\n",
    "            \"fundamentals\": fundamentals,\n",
    "            \"earnings_event\": earnings_event,\n",
    "            \"rationale\": \" | \".join(rationale) if rationale else None,\n",
    "            \"fetch_seconds\": round((datetime.now() - start_ts).total_seconds(), 2),\n",
    "            \"data_source\": \"yfinance\"\n",
    "        }\n",
    "\n",
    "        # Create payload\n",
    "        payload = {\n",
    "            \"symbol\": symbol,\n",
    "            \"rating\": rating,\n",
    "            \"confidence\": confidence,\n",
    "            \"timestamp\": start_ts.isoformat() + \"Z\",\n",
    "            \"source\": self.SOURCE,\n",
    "            \"context\": context\n",
    "        }\n",
    "        return payload\n",
    "\n",
    "# run Yahoo Finance Analysis as an Agent\n",
    "def run_yahoo_finance_agent(inputs: dict) -> dict:\n",
    "    symbol = inputs.get(\"ticker\")\n",
    "    agent = YahooFinanceAgent()\n",
    "    result = agent.analyze(symbol)\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    test_inputs = {\"ticker\": \"AAPL\"}\n",
    "    output = run_yahoo_finance_agent(test_inputs)\n",
    "    print(json.dumps(output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95367cb8",
   "metadata": {},
   "source": [
    "## /src/researchers/FREDresearcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import inspect\n",
    "import json\n",
    "import logging\n",
    "from typing import Any, Callable, Dict, Optional, TypedDict\n",
    "\n",
    "# CrewAI tool base\n",
    "try:\n",
    "    from pydantic import BaseModel, Field\n",
    "    from crewai.tools import BaseTool\n",
    "except Exception as e:  # pragma: no cover\n",
    "    raise ImportError(\n",
    "        \"CrewAI and Pydantic are required. Install with: pip install crewai pydantic\"\n",
    "    ) from e\n",
    "\n",
    "# Import FRED tools\n",
    "try:\n",
    "    from tools import fred_tools as fred_agent\n",
    "except ImportError:\n",
    "    from researchers.tools import fred_tools as fred_agent\n",
    "\n",
    "# Setup logging\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# load OpenAI client\n",
    "def _load_openai_client() -> OpenAI:\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "    return OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Define FRED State TypedDict\n",
    "class FREDState(TypedDict, total=False):\n",
    "    query: str\n",
    "    context: Dict[str, Any]\n",
    "    result: Any\n",
    "\n",
    "# Define FREDAgentAdapter\n",
    "class FREDAgentAdapter:\n",
    "    def __init__(self, module=fred_agent):\n",
    "        self._module = module\n",
    "        self._entrypoint = getattr(module, \"main\")\n",
    "        self.client = _load_openai_client()\n",
    "\n",
    "    def run(self, query: str, context=None):\n",
    "        # Treat query as ticker\n",
    "        return self._entrypoint(query)\n",
    "\n",
    "# Create CrewAI FRED Agent\n",
    "def create_crewai_fred_agent(agent_class):\n",
    "    \"\"\"\n",
    "    Create a CrewAI agent for FRED economic analysis.\n",
    "    \"\"\"\n",
    "    agent = FREDAgentAdapter()\n",
    "    \n",
    "    class FREDAnalysisTool(BaseTool):\n",
    "        name: str = \"fred_analysis\"\n",
    "        description: str = \"Analyzes economic indicators from FRED to assess their impact on a given stock ticker\"\n",
    "\n",
    "        def _run(self, query: str) -> Dict[str, Any]:\n",
    "            return agent.run(query)\n",
    "\n",
    "        async def _arun(self, query: str) -> Dict[str, Any]:\n",
    "            return self._run(query)\n",
    "\n",
    "    # Create the agent instance\n",
    "    return agent_class(\n",
    "        name=\"FRED Economic Analyst\",\n",
    "        role=\"Economic Research Specialist\",\n",
    "        goal=\"Analyze macroeconomic indicators from FRED to assess their impact on specific stocks\",\n",
    "        backstory=\"\"\"You are an expert economic analyst with deep knowledge of how \n",
    "        macroeconomic indicators affect stock performance. You use FRED data to provide \n",
    "        insights about the economic environment's impact on specific companies.\"\"\",\n",
    "        allow_delegation=False,\n",
    "        tools=[FREDAnalysisTool()]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2eeed",
   "metadata": {},
   "source": [
    "## /src/researchers/tools/fred_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fred_tools.py - Core FRED analysis functionality\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from fredapi import Fred\n",
    "import openai\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "def get_fred_data(ticker: str, api_key: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch and analyze economic indicators from FRED that might impact the given ticker.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): The stock symbol to analyze\n",
    "        api_key (str, optional): FRED API key. If not provided, will try to get from environment.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results with rating and context\n",
    "    \"\"\"\n",
    "    # Initialize FRED API\n",
    "    fred_key = api_key or os.getenv('FRED_API_KEY')\n",
    "    if not fred_key:\n",
    "        raise ValueError(\"FRED API key must be provided or set in FRED_API_KEY environment variable\")\n",
    "        \n",
    "    fred = Fred(api_key=fred_key)\n",
    "    \n",
    "    # Core economic indicators\n",
    "    indicators = {\n",
    "        'CPIAUCSL': 'Consumer Price Index',\n",
    "        'UNRATE': 'Unemployment Rate',\n",
    "        'FEDFUNDS': 'Federal Funds Rate',\n",
    "        'GDP': 'Gross Domestic Product',\n",
    "        'INDPRO': 'Industrial Production Index'\n",
    "    }\n",
    "    \n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "    \n",
    "    economic_data = {}\n",
    "    \n",
    "    try:\n",
    "        # Fetch economic indicators\n",
    "        for series_id, description in indicators.items():\n",
    "            series = fred.get_series(\n",
    "                series_id,\n",
    "                observation_start=start_date.strftime('%Y-%m-%d'),\n",
    "                observation_end=end_date.strftime('%Y-%m-%d')\n",
    "            )\n",
    "            \n",
    "            if not series.empty:\n",
    "                latest_value = series.iloc[-1]\n",
    "                previous_value = series.iloc[-2] if len(series) > 1 else None\n",
    "                pct_change = ((latest_value - previous_value) / previous_value * 100) if previous_value else None\n",
    "                \n",
    "                economic_data[series_id] = {\n",
    "                    'description': description,\n",
    "                    'latest_value': latest_value,\n",
    "                    'previous_value': previous_value,\n",
    "                    'pct_change': pct_change,\n",
    "                    'last_updated': series.index[-1].strftime('%Y-%m-%d')\n",
    "                }\n",
    "        \n",
    "        # Generate analysis using OpenAI\n",
    "        return analyze_economic_data(economic_data, ticker)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"rating\": 3,  # Neutral rating on error\n",
    "            \"analysis\": f\"Error fetching FRED data: {str(e)}\",\n",
    "            \"details\": {\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        }\n",
    "\n",
    "def analyze_economic_data(economic_data: Dict[str, Any], ticker: str) -> Dict[str, Any]:\n",
    "    \"\"\"Generate analysis of economic data using OpenAI.\"\"\"\n",
    "    openai_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not openai_key:\n",
    "        raise ValueError(\"OpenAI API key must be set in OPENAI_API_KEY environment variable\")\n",
    "        \n",
    "    openai.api_key = openai_key\n",
    "    \n",
    "    # Prepare economic data for the prompt\n",
    "    data_points = []\n",
    "    for series_id, data in economic_data.items():\n",
    "        data_points.append(\n",
    "            f\"{data['description']}: Current value: {data['latest_value']:.2f}, \"\n",
    "            f\"Change: {data['pct_change']:.2f}% (as of {data['last_updated']})\"\n",
    "        )\n",
    "    \n",
    "    economic_context = \"\\n\".join(data_points)\n",
    "    \n",
    "    prompt = f\"\"\"As an economic analyst, analyze how these core economic indicators might impact {ticker} stock:\n",
    "\n",
    "    Economic Indicators:\n",
    "    {economic_context}\n",
    "\n",
    "    Provide two things:\n",
    "    1. A rating from 1-5 (where 1 is very unfavorable and 5 is very favorable) based on how the current economic environment affects {ticker}'s prospects.\n",
    "    \n",
    "    2. A brief analysis explaining the rating and key economic factors affecting {ticker}.\n",
    "\n",
    "    Format your response as:\n",
    "    RATING: [number 1-5]\n",
    "    ANALYSIS: [your brief explanation]\"\"\"\n",
    "\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert economic analyst providing insights based on FRED economic data.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=300,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        response_text = response.choices[0].message.content\n",
    "        \n",
    "        # Parse the response\n",
    "        try:\n",
    "            rating_line = [line for line in response_text.split('\\n') if line.startswith('RATING:')][0]\n",
    "            analysis_line = [line for line in response_text.split('\\n') if line.startswith('ANALYSIS:')][0]\n",
    "            \n",
    "            rating = int(rating_line.split(':')[1].strip())\n",
    "            analysis = analysis_line.split(':')[1].strip()\n",
    "            \n",
    "            return {\n",
    "                \"rating\": rating,\n",
    "                \"analysis\": analysis,\n",
    "                \"details\": {\n",
    "                    \"indicators\": economic_data,\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "            }\n",
    "        except (IndexError, ValueError) as e:\n",
    "            return {\n",
    "                \"rating\": 3,\n",
    "                \"analysis\": f\"Error parsing analysis: {response_text}\",\n",
    "                \"details\": {\n",
    "                    \"error\": str(e),\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"rating\": 3,\n",
    "            \"analysis\": f\"Error generating analysis: {str(e)}\",\n",
    "            \"details\": {\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        }\n",
    "\n",
    "def main(ticker: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Main entry point for FRED analysis\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker to analyze\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results with rating and context\n",
    "    \"\"\"\n",
    "    return get_fred_data(ticker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f681f",
   "metadata": {},
   "source": [
    "## /src/researchers/News_Agent_Crew.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "\n",
    "try:\n",
    "    from News_Agent import NewsAgent  \n",
    "except ImportError:\n",
    "    from researchers.News_Agent import NewsAgent\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize LLM (Gemini 2.5 Flash) \n",
    "llm = LLM(\n",
    "    model=\"gemini/gemini-2.5-flash\",\n",
    "    api_key=os.getenv(\"G_API_KEY\")  # Google Gemini API key\n",
    ")\n",
    "\n",
    "# Define function to call your custom NewsAgent\n",
    "def run_news_agent(company: str):\n",
    "    \"\"\"\n",
    "    Runs the NewsAgent workflow for a given company and returns the result.\n",
    "    \"\"\"\n",
    "    agent = NewsAgent(\n",
    "        gemini_api_key=os.getenv(\"G_API_KEY\"),\n",
    "        news_api_key=os.getenv(\"NEWS_API_KEY\")\n",
    "    )\n",
    "    result = agent.run(company)\n",
    "    try:\n",
    "        return json.loads(result)  # parse JSON string if valid\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Invalid JSON returned by NewsAgent\", \"raw_result\": result}\n",
    "\n",
    "# Define CrewAI Agent \n",
    "news_agent_wrapper = Agent(\n",
    "    role=\"News Analysis Agent\",\n",
    "    goal=\"Fetch and analyze recent news for a given company and summarize sentiment.\",\n",
    "    backstory=\"This agent uses NewsAgent to collect and analyze company-related news articles.\",\n",
    "    llm=llm,  # Attach Gemini as the reasoning model\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define CrewAI Task \n",
    "news_agent_task = Task(\n",
    "    description=\"Run NewsAgent workflow for {company} and return analysis result.\",\n",
    "    expected_output=\"\"\" \n",
    "    Required JSON format:\n",
    "    {\n",
    "  \"company\": \"{company}\",\n",
    "  \"date\": \"<ISO8601 timestamp of analysis>\",\n",
    "  \"sentiment_summary\": {\n",
    "      \"overall_sentiment\": \"<Positive | Neutral | Negative>\",\n",
    "      \"positive_articles\": <number>,\n",
    "      \"neutral_articles\": <number>,\n",
    "      \"negative_articles\": <number>,\n",
    "      \"main_topic\": [\"theme 1\", \"theme 2\", \"...\"],\n",
    "      \"good_news\": [\"point 1\", \"point 2\", \"...\"],\n",
    "      \"bad_news\": [\"point 1\", \"point 2\", \"...\"],\n",
    "      \"neutral_news\": [\"point 1\", \"point 2\", \"...\"]\n",
    "  },\n",
    "  \"feedback\": \"<short summary evaluating completeness and quality of analysis>\"\n",
    "} \n",
    "\n",
    "Rules:\n",
    "1. Always return valid JSON only ‚Äî no explanations, markdown, or extra text.\n",
    "2. Always include all keys exactly as shown.\n",
    "3. Count the number of articles correctly for each sentiment.\n",
    "4. Summaries (main_topic, good_news, bad_news, feedback) should be concise and informative.\n",
    "5. Dates must be in ISO8601 format (YYYY-MM-DDTHH:MM:SS).\n",
    "\"\"\",\n",
    "    agent=news_agent_wrapper,\n",
    "    function= run_news_agent,\n",
    "    )\n",
    "\n",
    "\n",
    "# Define Crew \n",
    "news_agent_crew = Crew(\n",
    "    agents=[news_agent_wrapper],\n",
    "    tasks=[news_agent_task],\n",
    "    process=Process.sequential,\n",
    ")\n",
    "\n",
    "# Optional test run \n",
    "if __name__ == \"__main__\":\n",
    "    print(\" Running NewsAgent CrewAI pipeline...\\n\")\n",
    "    result = news_agent_crew.kickoff(inputs={\"company\": \"Microsoft\"})\n",
    "    print(\"\\n Final Result:\")\n",
    "    # Try to get the JSON safely\n",
    "    try:\n",
    "        # Check if CrewAI result is a dict already\n",
    "        if hasattr(result, \"raw\"):\n",
    "            clean_output = result.raw.strip('`').strip()\n",
    "            if clean_output.startswith(\"json\"):\n",
    "                clean_output = clean_output[4:].strip()\n",
    "            parsed = json.loads(clean_output)\n",
    "        else:\n",
    "            # Already a dict\n",
    "            parsed = result\n",
    "    except json.JSONDecodeError:\n",
    "        parsed = {\"error\": \"Invalid JSON returned by NewsAgent\", \"raw_result\": getattr(result, \"raw\", str(result))}\n",
    "\n",
    "    # Pretty print\n",
    "    print(json.dumps(parsed, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d93a6e",
   "metadata": {},
   "source": [
    "## /src/researchers/News_Agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a89b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "load_dotenv() \n",
    "\n",
    "class NewsAgent:\n",
    "    def __init__(self, gemini_api_key, news_api_key=None):\n",
    "        \"\"\"Initialize agent with memory and APIs.\"\"\"\n",
    "        self.news_api_key = news_api_key\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "        self.memory = {}  # store previous company analyses\n",
    "\n",
    "    # Planning: decide workflow steps \n",
    "    def plan_steps(self, company):\n",
    "        return [\"fetch_news\", \"analyze_sentiment\", \"self_reflect\", \"iterate_if_needed\"]\n",
    "\n",
    "   # Tool: fetch news \n",
    "    def fetch_news(self, company, max_articles=10):\n",
    "        \"\"\"Fetch recent news for the specified company, filtering only relevant articles.\"\"\"\n",
    "        if not self.news_api_key:\n",
    "            # Dummy fallback if no API key provided\n",
    "            return [\n",
    "                f\"{company} quarterly earnings positive\",\n",
    "                f\"{company} launches new product\",\n",
    "                f\"{company} market analysis favorable\",\n",
    "                f\"{company} competitor developments\",\n",
    "                f\"{company} regulatory updates\"\n",
    "            ][:max_articles]\n",
    "\n",
    "        company_name = company.lower()\n",
    "        url = f\"https://newsapi.org/v2/everything?q={company_name}&sortBy=publishedAt&apiKey={self.news_api_key}&language=en&pageSize={max_articles*2}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            if data.get(\"status\") != \"ok\":\n",
    "                return [f\"NewsAPI error: {data.get('message', 'Unknown error')}\"]\n",
    "\n",
    "            articles = data.get(\"articles\", [])\n",
    "            # Filter articles by company name in title or description\n",
    "            relevant_articles = [\n",
    "                article for article in articles\n",
    "                if company_name in article.get(\"title\", \"\").lower()\n",
    "                or company_name in (article.get(\"description\") or \"\").lower()\n",
    "            ]\n",
    "\n",
    "            if not relevant_articles:\n",
    "                return [f\"No recent news articles found for {company}\"]\n",
    "\n",
    "            return [\n",
    "                f\"{article.get('title', 'No title')} ({article.get('source', {}).get('name', 'Unknown source')})\"\n",
    "                for article in relevant_articles[:max_articles]\n",
    "            ]\n",
    "\n",
    "        except Exception as e:\n",
    "            return [f\"Error fetching news: {str(e)}\"]\n",
    "\n",
    "\n",
    "    #  Analyze sentiment and summarize \n",
    "    def analyze_sentiment(self, news_articles):\n",
    "        text = \"\\n\".join(news_articles[:10])\n",
    "        prompt = f\"\"\"\n",
    "You are a financial news sentiment analyzer.\n",
    "1. Classify each article as Positive, Negative, or Neutral.\n",
    "2. Extract key risks and opportunities.\n",
    "3. Summarize overall sentiment for the company.\n",
    "\n",
    "Articles:\n",
    "{text}\n",
    "\"\"\"\n",
    "        response = self.model.generate_content(prompt)\n",
    "        return response.text\n",
    "    \n",
    "    # Reanalyze only new or uncovered information\n",
    "    def reanalyze_sentiment(self, new_articles, previous_summary):\n",
    "        text = \"\\n\".join(new_articles[:10])\n",
    "        prompt = f\"\"\"\n",
    "    You are a financial news sentiment analyzer refining a previous analysis.\n",
    "\n",
    "    Your goal:\n",
    "- Identify ONLY truly new insights, opportunities, risks, or sentiment shifts not mentioned before.\n",
    "- show the article that provides the new insight\n",
    "- Avoid repeating or restating anything already covered.\n",
    "- Keep it short, plain, and non-academic (no jargon).\n",
    "\n",
    "    Previous summary:\n",
    "    {previous_summary}\n",
    "\n",
    "    New articles:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "        response = self.model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    # Self-reflection: evaluate analysis quality \n",
    "    def self_reflect(self, company, analysis):\n",
    "        prompt = f\"\"\"\n",
    "You are a financial research agent.\n",
    "Evaluate the following analysis for {company}. \n",
    "- Does it cover key risks and opportunities?\n",
    "- Is the overall sentiment clear?\n",
    "- Suggest improvements if needed.\n",
    "\n",
    "Analysis:\n",
    "{analysis}\n",
    "\"\"\"\n",
    "        response = self.model.generate_content(prompt)\n",
    "        feedback = response.text\n",
    "        return feedback\n",
    "\n",
    "    # Iteration: refine based on feedback \n",
    "    def iterate(self, company, feedback, previous_analysis=None):\n",
    "        if \"improve\" in feedback.lower():\n",
    "            news = self.fetch_news(company, max_articles=15)  # fetch more\n",
    "            new_analysis = self.reanalyze_sentiment(news, previous_summary=previous_analysis or \"\")\n",
    "            return new_analysis\n",
    "        return None\n",
    "\n",
    "    # Run the full agent workflow \n",
    "    def run(self, company):\n",
    "        print(f\" Planning steps for: {company}\")\n",
    "        steps = self.plan_steps(company)\n",
    "\n",
    "        # Check memory first\n",
    "        if company in self.memory:\n",
    "            print(f\"Found previous analysis for {company} in memory. Using it as base.\")\n",
    "            previous_result = self.memory[company]\n",
    "            previous_news = previous_result.get(\"articles\", [])\n",
    "            previous_analysis = previous_result.get(\"refined_analysis\", None)\n",
    "        else:\n",
    "            previous_news = []\n",
    "            previous_analysis = None\n",
    "\n",
    "        news = []\n",
    "        analysis = previous_analysis\n",
    "        feedback = None\n",
    "        refined = None\n",
    "\n",
    "        for step in steps:\n",
    "            if step == \"fetch_news\":\n",
    "                print(\"‚Üí Fetching news...\")\n",
    "                news = self.fetch_news(company)\n",
    "                if previous_news:\n",
    "                    news = previous_news + news\n",
    "                print(f\"  Found {len(news)} articles:\")\n",
    "                for i, article in enumerate(news, 1):\n",
    "                    print(f\"    Article {i}: {article}\\n\")\n",
    "\n",
    "            elif step == \"analyze_sentiment\":\n",
    "                print(\"‚Üí Analyzing sentiment...\")\n",
    "                if not analysis:\n",
    "                    analysis = self.analyze_sentiment(news)\n",
    "                print(\"  Sentiment analysis complete. Details:\\n\")\n",
    "                print(analysis)\n",
    "            elif step == \"self_reflect\":\n",
    "                print(\"‚Üí Self-reflection in progress...\")\n",
    "                feedback = self.self_reflect(company, analysis)\n",
    "                print(\"  Self-reflection complete. Feedback:\\n\")\n",
    "                print(feedback)\n",
    "\n",
    "            elif step == \"iterate_if_needed\":\n",
    "                print(\"‚Üí Iterating if needed...\")\n",
    "                refined = self.iterate(company, feedback, previous_analysis=analysis)\n",
    "                if refined:\n",
    "                    analysis = refined\n",
    "                    print(\"  Refined analysis applied:\\n\")\n",
    "                    print(refined)\n",
    "\n",
    "\n",
    "        # Prepare JSON-like output \n",
    "        result = {\n",
    "            \"agent\": \"NewsAgent\",\n",
    "            \"company\": company,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"articles\": news,\n",
    "            \"sentiment_summary\": analysis,\n",
    "            \"feedback\": feedback,\n",
    "            \"refined_analysis\": refined or analysis\n",
    "        }\n",
    "\n",
    "        # Save to memory\n",
    "        self.memory[company] = result\n",
    "        print(f\" Workflow complete. Memory updated for {company}.\")\n",
    "\n",
    "        # Return as JSON string (for easy integration later)\n",
    "        return json.dumps(result, indent=2)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent = NewsAgent(\n",
    "        gemini_api_key=os.getenv(\"G_API_KEY\"),\n",
    "        news_api_key=os.getenv(\"API_KEY\")\n",
    "    )\n",
    "    result_json = agent.run(\"Microsoft\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8ef63",
   "metadata": {},
   "source": [
    "Coding assistants and other sources like Gemeni and ChatGPT were used to help create the code in this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
